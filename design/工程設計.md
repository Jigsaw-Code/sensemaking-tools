# Sensemaker 專案：從 Vertex AI 遷移到 OpenRouter 工程設計

## 專案概述

本專案旨在將 Sensemaker 工具從 Google Cloud Vertex AI 遷移到 OpenRouter，以提供更靈活的模型選擇和成本控制。遷移過程將保持原有功能的完整性，同時新增對多個 AI 模型提供者的支援。

## 現狀分析

### 現有架構
- **核心模型類別**: `VertexModel` 繼承自抽象 `Model` 類別
- **Prompt 處理**: 統一的 prompt 建構函數 (`getPrompt`, `getAbstractPrompt`)
- **API 呼叫**: 透過 `callLLM` 方法處理速率限制、重試和回應驗證
- **結構化輸出**: 支援 JSON Schema 驗證的 `generateData` 方法

### 關鍵依賴
- `@google-cloud/vertexai`: Vertex AI SDK
- `@sinclair/typebox`: JSON Schema 驗證
- `p-limit`: 並發控制

## 遷移目標

1. **功能完整性**: 保持所有現有功能不變
2. **向後相容**: 現有程式碼無需修改即可使用新實作
3. **擴展性**: 支援多個 AI 模型提供者
4. **成本優化**: 透過 OpenRouter 的競爭定價降低 API 成本
5. **測試覆蓋**: 確保新實作通過所有現有測試

## 開發階段規劃

### 第一階段：基礎架構建立

#### 1.1 建立 OpenRouter 模型類別
- **檔案**: `library/src/models/openrouter_model.ts`
- **任務**:
  - 實作 `Model` 抽象類別的具體實作
  - 整合 OpenRouter API 呼叫
  - 實作速率限制和重試機制
  - 支援結構化輸出 (JSON Schema)

#### 1.2 建立 OpenRouter 工具類別
- **檔案**: `library/src/models/openrouter_util.ts`
- **任務**:
  - 定義 OpenRouter 相關常數
  - 實作 API 金鑰管理
  - 定義預設模型設定
  - 實作請求格式轉換

#### 1.3 更新環境變數設定
- **檔案**: `.env.example` (新增)
- **任務**:
  - 新增 `dotenv` 依賴管理環境變數
  - 定義 OpenRouter API 金鑰
  - 設定預設模型選擇
  - 設定速率限制參數

### 第二階段：核心功能實作

#### 2.1 實作 OpenRouter API 整合
- **任務**:
  - 實作 HTTP 請求到 OpenRouter API
  - 處理不同的模型回應格式
  - 實作錯誤處理和重試邏輯
  - 支援串流和非串流回應

#### 2.2 實作 Prompt 處理
- **任務**:
  - 保持與現有 `getPrompt` 函數的相容性
  - 實作 OpenRouter 特定的 prompt 格式化
  - 支援不同模型的 prompt 要求

#### 2.3 實作結構化輸出
- **任務**:
  - 實作 JSON Schema 驗證
  - 處理不同模型的 JSON 輸出格式
  - 實作回應解析和錯誤處理

### 第三階段：測試和驗證 

#### 3.1 單元測試
- **檔案**: `library/src/models/openrouter_model.test.ts`
- **任務**:
  - 測試模型初始化和設定
  - 測試 prompt 處理和 API 呼叫
  - 測試錯誤處理和重試機制
  - 測試結構化輸出驗證

#### 3.2 整合測試
- **檔案**: `library/src/models/openrouter_integration.test.ts`
- **任務**:
  - 測試與現有 prompt 函數的整合
  - 測試與不同任務模組的相容性
  - 測試端到端的工作流程

#### 3.3 效能測試
- **任務**:
  - 測試 API 回應時間
  - 測試並發處理能力
  - 測試速率限制效果
  - 與 Vertex AI 的效能比較

### 第四階段：配置和部署

#### 4.1 模型設定管理
- **檔案**: `library/src/models/model_factory.ts` (新增)
- **任務**:
  - 實作模型選擇邏輯
  - 支援環境變數配置
  - 實作模型切換機制

#### 4.2 配置文件更新
- **檔案**: `library/config/models.json` (新增)
- **任務**:
  - 定義支援的模型清單
  - 設定模型特定參數
  - 配置預設模型選擇
  - 更新 `package.json` 新增 `dotenv` 依賴

#### 4.3 文檔更新
- **檔案**: `library/docs/openrouter_migration.md` (新增)
- **任務**:
  - 撰寫遷移指南
  - 更新 API 文檔
  - 提供配置範例

### 第五階段：優化和清理 (1-2 天)

#### 5.1 效能優化
- **任務**:
  - 優化 API 呼叫效率
  - 改善錯誤處理邏輯
  - 優化記憶體使用

#### 5.2 程式碼清理
- **任務**:
  - 移除未使用的程式碼
  - 改善程式碼註解
  - 統一程式碼風格

#### 5.3 最終測試
- **任務**:
  - 執行完整的測試套件
  - 驗證所有功能正常運作
  - 檢查效能指標

## 技術實作細節

### OpenRouter API 整合
```typescript
// 預期的 API 呼叫結構
interface OpenRouterRequest {
  model: string;
  messages: Array<{
    role: 'user' | 'assistant' | 'system';
    content: string;
  }>;
  temperature?: number;
  max_tokens?: number;
  response_format?: { type: 'json_object' };
}
```

### 模型切換機制
```typescript
// 支援的模型清單
const SUPPORTED_MODELS = {
  'anthropic/claude-3.5-sonnet': 'Claude 3.5 Sonnet',
  'openai/gpt-4o': 'GPT-4 Omni',
  'meta-llama/llama-3.1-8b-instruct': 'Llama 3.1 8B',
  'google/gemini-pro': 'Gemini Pro'
};
```

### 錯誤處理策略
- **API 錯誤**: 重試機制，指數退避
- **速率限制**: 自動延遲和重試
- **無效回應**: JSON 解析錯誤處理
- **網路錯誤**: 連線超時和重連

## 風險評估和緩解

### 高風險項目
1. **API 相容性**: OpenRouter 與 Vertex AI 的 API 差異
   - 緩解: 建立抽象層，統一 API 介面
2. **回應格式**: 不同模型的輸出格式差異
   - 緩解: 實作標準化回應處理器
3. **速率限制**: OpenRouter 的 API 限制
   - 緩解: 實作智能重試和延遲機制

### 中風險項目
1. **效能差異**: 不同模型的回應時間
   - 緩解: 實作效能監控和自動調整
2. **成本控制**: API 呼叫成本管理
   - 緩解: 實作使用量追蹤和警告

### 低風險項目
1. **配置管理**: 環境變數和設定檔
   - 緩解: 提供詳細的配置文檔和範例

## 成功標準

### 功能完整性
- [ ] 所有現有測試通過
- [ ] 支援所有現有功能
- [ ] 與現有程式碼完全相容

### 效能指標
- [ ] API 回應時間 < 10 秒 (95th percentile)
- [ ] 錯誤率 < 1%
- [ ] 並發處理能力 >= 現有實作

### 品質標準
- [ ] 程式碼覆蓋率 >= 90%
- [ ] 所有 lint 檢查通過
- [ ] 文檔完整且準確



## 後續改進

### 短期改進 (1-2 個月)
- 支援更多 OpenRouter 模型
- 實作模型效能比較工具
- 改善錯誤報告和監控

### 長期改進 (3-6 個月)
- 實作模型自動選擇
- 支援混合模型策略
- 實作成本優化建議

## 結論

本遷移專案將為 Sensemaker 工具提供更靈活的 AI 模型選擇，同時保持現有功能的完整性。透過分階段開發和充分的測試，我們可以確保遷移過程的順利進行，並為未來的擴展奠定堅實的基礎。
